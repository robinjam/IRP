\documentclass[conference]{IEEEtran}

\usepackage{draftwatermark}
\usepackage[backend=bibtex]{biblatex}

\addbibresource{report.bib}
\nocite{*}

\begin{document}

	\title{Lag compensation techniques for networked games}
	\author{\IEEEauthorblockN{James Robinson}
	\IEEEauthorblockA{Electronics and Computer Science\\
	University of Southampton\\
	Email: jr4e09@soton.ac.uk}}
	\maketitle

	\begin{abstract}
		In networked multiplayer games, network latency often introduces an unacceptable delay between when the player attempts to take an action and when the action actually takes effect within the game world. In this paper, methods of quantifying the effects of this latency, algorithms that mask its apparent effects, and a selection of novel unified frameworks for lag compensation are explored. Also discussed are the advantages and limitations of each algorithm, along with their potential applications.
	\end{abstract}

	\section{Introduction}

	% Explain what kinds of games we're talking about and general terminology
	% Assume tick-based games

	In gaming, the term ``lag'' refers to the delay between when the user takes an action, and when the action takes effect within the game world. Lag can be introduced by many factors including input device latency, framerate, vsync, and monitor response time, but the most egregious source of lag in networked or online games is the latency between client and server. Although techniques exist to reduce this latency, the fact that data transfer is limited by the speed of light means that this latency can never be completely eliminated.

	Lag reduces player engagement and enjoyment, and furthermore can impact performance in competitive multiplayer games \cite{beigbeder2004effects}. For this reason, most popular online games take measures to reduce the effect of network latency on the player's experience. Such techniques are generally referred to as ``lag compensation'' algorithms. Many such techniques exist, each of which make various tradeoffs that are appropriate for some types of game. Because of the disparate requirements of different genres of game, no ``silver bullet'' solution exists.

	In this paper, I will introduce various state of the art techniques for lag compensation in networked multiplayer games, discussing their advantages and disadvantages, as well as which types of simulation each technique is suited to. I will also present some unified models.

	\section{Quantifying effects of latency}

	TODO \cite{beigbeder2004effects} \cite{chen2011perceptual} \cite{claypool2005effect} \cite{fritsch2005effect} \cite{sheldon2003effect} \cite{quax2004objective} \cite{dick2005analysis}

	\section{Dead reckoning}

	The simplest form of client-side lag compensation is ``dead reckoning'' (named for the principle used in navigation). Under this approach, the last known positions and velocities of each game object are used to predict their current position via extrapolation, taking latency into account. For example, given current time $t$, current latency $l$, and a game object with last known position $\hat{s}_{t - l}$ and velocity $\hat{v}_{t - l}$, the predicted position at the current point in time is $\hat{s}_{t} = \hat{s}_{t - l} + l\hat{v}_{t - l}$. Figure~\ref{fig:extrapolation_timeline} shows a timeline of this approach: updates from the server take some amount of time to reach the client, and the client extrapolates game object positions to predict where they are now.

	\begin{figure}
		\centering\includegraphics[width=\linewidth]{figures/extrapolation_timeline.eps}
		\caption{A timeline showing extrapolation. The client predicts the current server time based on measured latency, and extrapolates object positions from the position and velocity data in the latest update received from the server ($t = 4$).}
		\label{fig:extrapolation_timeline}
	\end{figure}

	Misprediction errors are very common under this scheme, occurring every time the velocity or bearing of a game object changes. The simplest way to correct misprediction errors is to immediately ``snap'' the object to the correct location once an update arrives from the server, but this can cause very visible visual discontinuities that can be distracting for the player. A less accurate but visually smoother approach is to interpolate between the position that the entity was last rendered at and its current estimated position (as shown in figure~\ref{fig:extrapolation}). This smooths out the visual discontinuities but also further reduces precision.

	\begin{figure}
		\centering\includegraphics[width=\linewidth]{figures/extrapolation.eps}
		\caption{Misprediction. The client extrapolates object positions based on measured latency in order to predict where they are now. If objects change bearing, misprediction errors occur.}
		\label{fig:extrapolation}
	\end{figure}

	It is important to note that when using this scheme, game objects are very rarely (if ever) rendered at correct, accurate positions. This tradeoff is acceptable for some games, particularly where game objects change velocity or bearing reasonably slowly (for example, cars in a racing game) \cite{pantel2002suitability}, but for games requiring pinpoint accuracy, a better scheme is required.

	% Sometimes use high-order differential coefficients http://www.mine-control.com/zack/timesync/timesync.html

	\Textcite{pantel2002suitability} discusses the suitability of Dead Reckoning schemes for games. The authors classify prediction schemes into two categories: prediction of positions, and prediction of input events. Within these categories they defined 7 different prediction schemes:

	\subsection{Position prediction schemes}

	\begin{enumerate}
		\item Assume objects are moving at a constant velocity, and extrapolate their new positions from their old ones
		\item Assume objects are experiencing constant acceleration, extrapolate their velocity and thus their position
		\item The same as scheme 2, but using a Lagrange polynom of degree 2 (commonly used for interpolation and extrapolation in 3D graphics)
		\item Assume objects are moving at a constant velocity, and use this to plot their trajectory
	\end{enumerate}

	\subsection{Input event prediction schemes}

	\begin{enumerate}
		\setcounter{enumi}{4}
		\item Assume control device (i.e. joystick) positions remain constant, and predict the effect this input will have on the game object
		\item Assume control device velocity remains constant
		\item Assume control device acceleration remains constant, and extrapolate velocity using a degree 2 Lagrange polynom
	\end{enumerate}

	The authors considered applications of these prediction schemes to 3 different types of game: sports games, 3D action games, and simulators/racing games. A simple model was constructed for each type of game in order to assess the viability of each prediction scheme. For sports games, a ``cursor-like steering model'' was used -- game objects steer towards a point within the game world. For both action games and racing games, game objects were assumed to behave like vehicles -- the x axis of the control device manipulates the direction of the game object, and the y axis controls its acceleration. The quality of a prediction scheme was defined as the average deviation between game object positions calculated by the game engine, and their predicted positions.

	The results were surprising: the most complex schemes did not always lead to the best results. For example, scheme 5 was particularly successful despite its simplicity. For sports games, scheme 6 produced the lowest average deviation, with all input-based prediction methods faring reasonably well. For action games, scheme 7 fared best. Because of the proprietary physics engine used in the racing game example, it was only possible to evaluate position-based prediction. Schemes 2 and 3 performed equally well.

	There are a number of issues with the approach presented in the paper:

	\begin{itemize}
		\item The model used to simulate action games is fundamentally unrealistic; characters in a first-person shooter do not behave like vehicles. Instead, players are able to move freely in any direction, rather than being constrained to motion in the direction they're facing. Players in shooter games also tend to move far more eratically than in the demonstration from the paper.
		\item Using input prediction schemes for a competitive multiplayer action game might be infeasible for the same reason that input prediction failed for racing/simulation games in the paper: most action games use proprietary physics engines, many of them involving incredibly complex interactions between game objects and the environment (explosions, destructible terrain, etc.). Prediction is very difficult in such games, hence the ubiquity of the delayed presentation approach.
	\end{itemize}

	The results presented in the paper are misleading at best -- prediction likely does not work as well for action games as the authors claim. However, the novel prediction techniques presented for both racing games and sports games do perform better than the naive approach, and might see use in future titles.

	\Textcite{Simpson2000} describes a technique for improving the accuracy of dead reckoning via the use of a novel clock synchronisation algorithm. The author evaluates the possibility of using existing algorithms such as NTP, but concludes that because NTP is so difficult to implement and takes so long to converge, it is unsuitable for a game in which the player expects to be able to ``jump in'' rather than waiting for clock synchronisation to converge.

	The proposed clock synchronisation algorithm is essentially a moving average latency calculation built upon TCP. The client periodically sends ``time request'' packets timestamped with the local time to the server, and the server sends back a timestamped response. The client subtracts the time when the response was received from the time when the request was sent in order to determine the round-trip time between client and server, halving this to obtain the latency, and takes the delta between the timestamp of the sent message and the timestamp of the received message, adding the latency to produce a clock delta. This process is repeated a number of times to produce an ordered list of clock deltas, and the median is taken. Samples that are further than 1 standard deviation from the mean are discarded. Finally, the local clock is adjusted based on this delta in order to synchronise the local and remote clocks.

	This algorithm is intended to be used in tandem with timestamped updates to improve the accuracy of dead reckoning algorithms in networks with high variance in packet delivery times (``jitter''). It was implemented in \emph{NetStorm, Islands At War} (a commerial real-time strategy game) with good results, typically obtaining synchronisations less than 100ms.

	\emph{Accuracy in Dead-Reckoning Based Distributed Multi-Player Games}

	\begin{itemize}
		\item Focuses on accuracy
		\item Primarily applicable to distributed/p2p games
		\item Peers generate DR vectors for entities under their control, which consist of a position and velocity, and broadcast them to other peers
		\item Without clock synchronisation, it's difficult to estimate what time a received packet was sent, and so entities can't be predicted accurately
		\item Can't rely on latency to server since there is no server
		\item Solution: synchronize clocks between peers and include timestamps in DR vectors
		\item Implemented their new technique in BZFlag and compared against old technique; significant quantitative improvement, even with latency as high as 100ms
		\item Not necessarily directly applicable to all action games; in BZFlag players control tanks that are constrained to traditional vehicle movement, much like a racing game.
	\end{itemize}

	\Textcite{cai1999auto} describe an auto-adaptive dead reckoning algorithm for distributed interactive simulations, which might also be applicable to peer to peer games. In general, distributed simulations built using dead-reckoning must make a tradeoff between prediction accuracy and bandwidth; by sending fewer position updates bandwidth may be conserved, at the cost of prediction accuracy. Many distributed systems operate by withholding position updates until the error between the actual position of an entity and its predicted position goes over some fixed threshold. The benefit of this approach is that by altering the threshold, the tradeoff between accuracy and bandwidth can be adjusted. However, not all clients need accurate location data for all entities (for example, a player does not need particularly accurate position information for another player a significant distance away), and so using a fixed threshold for every game object is inefficient.

	The authors address this limitation by introducing the concept of \emph{threshold levels}. Each game object has a defined \emph{area of interest} (AoI), sometimes called the \emph{reachability region}, which is a circle around the game object whose radius is usually related to the type of object. The area of interest represents the region in which dead reckoning accuracy is important from the perspective of that game object. Furthermore, each game object has a \emph{sensitive region} (SR); if another game object moves within a game object's SR, a collision is likely to occur. The authors define 4 different threshold levels based upon the interactions between the AoI and SR of the game objects and the relative distance between them.

	This algorithm requires each simulator to maintain the last known positions of all game objects, both local and remote. After each update of the game object controlled by a simulator, the true position of the entity is compared with the predicted positions at other simulators - if the difference is greater than the threshold, then a position update is sent.

	The primary drawback of this approach is memory consumption: in a system with $N$ entities controlled by $N$ simulators, each simulator must maintain not only its own state, but also the last known position of the controlled game object by each of the other $N - 1$ simulators.

	\section{Delayed input}

	e.g. GGPO

	Bucket synchronization

	Local lag

	\section{Delayed presentation}

	An alternative approach to client-side lag compensation is to buffer updates received from the server for some time before rendering them. By doing this, the client can ensure that it always has at least two ``real'' world states between which it can interpolate, which completely eliminates the misprediction errors mentioned previously. A timeline showing this approach is given in figure~\ref{fig:interpolation_timeline}. Note that because the client buffers 3 updates, this system is also tolerant of occasional packet loss; the client always has at least 2 snapshots to interpolate between, even if 1 packet goes missing.

	An immediately apparent problem with this approach is that while reducing the apparent effects of latency, it actually \emph{induces} additional latency by virtue of ``queuing up'' updates before they are rendered. Thus prediction must be applied to the game object controlled by the player in order to maintain interactivity.

	If the client runs out of buffered packets (due to packet loss or server error), it may either freeze until a new state is received, or fall back to extrapolation. In the latter case, the same disadvantages detailed in the previous section occur.

	\begin{figure}
		\centering\includegraphics[width=\linewidth]{figures/interpolation_timeline.eps}
		\caption{A timeline showing delayed presentation. The client buffers updates received from the server for a short period instead of displaying them immediately. Under this scheme the client always has at least two snapshots to interpolate between, eliminating the need for prediction/dead reckoning.}
		\label{fig:interpolation_timeline}
	\end{figure}

	\section{Server-side lag compensation}

	\subsection{No compensation}

	The simplest approach to server-side lag compensation is to do nothing at all. If the clients are already predicting future world states via extrapolation, then the server doesn't need to do anything. If the clients are \emph{not} predicting future world states (for example, if they follow the buffering/interpolation approach detailed above), then a consequence of not applying server-side lag compensation is that players must lead their targets by an amount proportional to their latency and (if applicable) the interpolation period.

	\subsection{Authoritative clients}

	Another very simple approach is to make clients authoritative over their actions. For example, if the client says ``I am now at position X and I have killed player Y'', the server will just blindly accept this new information, move the player to position X, and mark player Y as dead. This only works if all clients can be trusted, which immediately rules out most real-world scenarios due to the possibility of cheating.

	\subsection{Buffering of world state}

	\cite{bernier2001latency}

	\begin{itemize}
		\item Buffer 1 sec of previous world states
		\item When a client command arrives, rewind time based on their latency and (if applicable) their interp amount, interpolating between wold states if the command occurred between ticks
		\item Execute the command in the context of this world state
		\item This can cause temporal paradoxes - players can be shot after they duck behind cover. Usually a tradeoff the developer is willing to make since it ensures responsiveness for all players
		\item If player latency varies too much (for example, if data follows many different routes), this is inaccurate. Works best if constant latency can be guaranteed
		\item Gives ``peek advantage'' when players go round corners, more pronounced if there is a large latency difference between the players in the exchange
	\end{itemize}

	\section{Network-level}

	TODO \cite{yu2008latency} \cite{yu2012latency}

	\section{Supporting technologies}

	\subsection{Clock synchronisation}

	TODO \cite{cristian1989probabilistic}

	\subsection{Delta encoding}

	No sources found yet, other than Quake 3 source code

	\section{Timelines: A unified framework}

	\Textcite{savery2013timelines} describe a unified approach to lag compensation built upon the concept of \emph{timelines}. Timelines are a data structure that ``expose the temporal dimension of shared data'', allowing the programmer to specify the known value of a variable at a specific point in time, and automatically and transparently handling the interpolation or extrapolation required to predict the value of that variable at a point in time where its actual value is unknown. Timelines are fully replicated, and each client has its own timeline object for each portion of the simulation it is interested in. This allows the programmer to manipulate the flow of time, or to create divergent timelines for different players.

	The timelines model simplifies and unifies existing lag compensation algorithms, allowing dead reckoning, smooth correction of misprediction errors, delayed input, and time-offsetting to be implemented with relative ease. The model addresses 3 primary issues that lag compensation techniques must handle.

	Firstly, the \emph{stale message problem} -- that there is no way to know when a received message was sent, due to variance in network delivery times (``jitter''). The timelines framework solves this problem by clock synchronisation and the inclusion of timestamps in each message.

	Secondly, the \emph{stale state problem} -- games typically display updates to the user very frequently (60 times per second for most titles), but in order to conserve bandwidth network updates are often sent at a lower frequency. In some games updates might also be delayed if a client can detect that another client can extrapolate the position of an entity accurately via dead reckoning. The client must therefore have some method of compensating for missing or suppressed updates (interpolation), and the ability to keep track of remote state.

	Thirdly, the \emph{frame of reference problem} -- some games deliberately alter the player's frame of reference (for example Half-Life 2, which uses delayed presentation). This increases the predictability of entities, but also allows state to diverge between players (i.e. each player has their own unique view of the world). To provide consistency and prevent cheating, the server must be able to ``rewind time'', to recreate a remote client's state when that remote client took an action. This is trivial within the timelines framework.

	Finally, the \emph{multiple times at once problem} -- some lag compensation techniques (for example, smooth correction of misprediction errors), require that the client be able to know past, present and future values of a given variable at the same time. By exposing the temporal dimension of the data to the programmer, such algorithms become trivial to implement.

	The model has some known limitations:

	\begin{itemize}
		\item It does not support multiple clients updating (writing) the same timeline at the same time, since each client might overwrite the values the other wrote. This could potentially be fixed by adding synchronisation primitives to the framework, but it is unclear when such a problem would arise in a real-world game, since typically only one is authoritative over a particular game object.
		\item It's unsuitable for serialization of large objects, since the entire shared object must be sent over the network with every update. By using custom serialisation functions that only transmit the fields of the object that have changed (``delta encoding'') it is possible to sidestep this problem, but further work is required to generalise this to apply to every type of object.
		\item Command type data (e.g. ``jump'', ``shoot'') is not handled in the timelines model since there is no meaningful way to ``interpolate'' or ``extrapolate'' such data. Instead, the application is expected to maintain a separate queue for such messages, or to use an event-driven approach.
	\end{itemize}

	An additional potential limitation of the model that is not addressed in the paper is that it does not assume a tick-based game engine. In the timelines framework, a doubly linked list is used to store known state values tagged by time. Finding the value of a shared variable at a particular point in time therefore requires traversal of the list, which involves a pointer dereference for each step (a highly cache-unfriendly operation). In most networked multiplayer games, the server operates on a fixed tick-rate, and values may only be updated during a tick. In such games, it might make more sense to represent timelines as arrays, where the array index represents the tick, and the value at that index represents the value of the variable at that tick. This could potentially reduce the time complexity of get and set operations against the timeline for tick-based games.

	\section{Conclusions}

	TODO

	\printbibliography

\end{document}
